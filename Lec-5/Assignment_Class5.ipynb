{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1JFpcGnYA-hJMFwdjZHkau_vcEQviAJwT","authorship_tag":"ABX9TyMEBCz95+A8qgTKxAQeX4yl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Automated File Management and Data Export System**"],"metadata":{"id":"1azJ-6VOH0sn"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"cjTyjlBTFKuT","executionInfo":{"status":"ok","timestamp":1740067638840,"user_tz":-300,"elapsed":13,"user":{"displayName":"Hamdia Nouman","userId":"10014278124936378523"}}},"outputs":[],"source":["import os\n","os.makedirs(\"csv_files\", exist_ok=True)\n","os.makedirs(\"backup_folder\", exist_ok=True)\n"]},{"cell_type":"code","source":["import os\n","import glob\n","import shutil\n","import pandas as pd\n","\n","# Move all CSV files to a backup folder\n","csv_files = glob.glob(\"*.csv\")\n","for file in csv_files:\n","    shutil.move(file, \"/content/backup_folder\")\n","    print(f\"Moved file: {file}\")\n","\n","# Automating Export\n","def export_data(df, filename, file_format):\n","    if file_format == \"csv\":\n","        df.to_csv(filename, index=False)\n","        print(f\"Data exported to {filename} in CSV format.\")\n","    elif file_format == \"json\":\n","        df.to_json(filename, orient=\"records\")\n","        print(f\"Data exported to {filename} in JSON format.\")\n","    else:\n","        print(\"Unsupported format.\")\n","\n","# Example usage:\n","# Creating a sample dataframe\n","data = {\n","    'Name': ['Alice', 'Bob', 'Charlie'],\n","    'Age': [25, 30, 35],\n","    'City': ['New York', 'Los Angeles', 'Chicago']\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Exporting to CSV\n","export_data(df, \"output.csv\", \"csv\")\n","\n","# Exporting to JSON\n","export_data(df, \"output.json\", \"json\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LEUq3MNAH7Qb","executionInfo":{"status":"ok","timestamp":1740067907558,"user_tz":-300,"elapsed":51,"user":{"displayName":"Hamdia Nouman","userId":"10014278124936378523"}},"outputId":"b80fabd7-5ab0-48d1-d7b3-aefc0905765f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Moved file: output.csv\n","Data exported to output.csv in CSV format.\n","Data exported to output.json in JSON format.\n"]}]},{"cell_type":"markdown","source":["**Real-Time Stock Market Data Collection and Analysis Using\n","Python and SQLite**"],"metadata":{"id":"QIn82yzQIgrs"}},{"cell_type":"code","source":["import yfinance as yf\n","import sqlite3\n","import pandas as pd\n","import time\n","\n","# Database setup\n","db_name = \"stocks.db\"\n","conn = sqlite3.connect(db_name)\n","cursor = conn.cursor()\n","\n","# Create table if not exists\n","cursor.execute('''CREATE TABLE IF NOT EXISTS stock_data (\n","                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n","                    symbol TEXT,\n","                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n","                    open REAL,\n","                    high REAL,\n","                    low REAL,\n","                    close REAL,\n","                    volume INTEGER)''')\n","conn.commit()\n","\n","# Function to fetch stock data\n","def fetch_stock_data(symbol):\n","    try:\n","        stock = yf.Ticker(symbol)\n","        data = stock.history(period=\"1d\", interval=\"1h\")\n","\n","        if data.empty:\n","            print(f\"No data found for {symbol}. Skipping...\")\n","            return None  # Return None if no data is available\n","\n","        latest = data.iloc[-1]  # Get the most recent price data\n","        return {\n","            \"symbol\": symbol,\n","            \"open\": latest[\"Open\"],\n","            \"high\": latest[\"High\"],\n","            \"low\": latest[\"Low\"],\n","            \"close\": latest[\"Close\"],\n","            \"volume\": latest[\"Volume\"]\n","        }\n","    except Exception as e:\n","        print(f\"Error fetching data for {symbol}: {e}\")\n","        return None\n","\n","# Function to store data in SQLite\n","def store_data(symbol):\n","    stock_data = fetch_stock_data(symbol)\n","    if stock_data:  # Only store if data is available\n","        cursor.execute('''INSERT INTO stock_data (symbol, open, high, low, close, volume)\n","                          VALUES (?, ?, ?, ?, ?, ?)''',\n","                       (stock_data[\"symbol\"], stock_data[\"open\"],\n","                        stock_data[\"high\"], stock_data[\"low\"],\n","                        stock_data[\"close\"], stock_data[\"volume\"]))\n","        conn.commit()\n","        print(f\"Stored data for {symbol}\")\n","\n","# Function to analyze stock data\n","def analyze_stock(symbol):\n","    df = pd.read_sql_query(\"SELECT * FROM stock_data WHERE symbol=? ORDER BY timestamp DESC LIMIT 100\",\n","                           conn, params=(symbol,))\n","    print(df)\n","\n","# Example Usage\n","symbol = \"SPY\"\n","\n","for _ in range(2):  # Fetch data 5 times with intervals\n","    store_data(symbol)\n","    time.sleep(120)  # Wait for 1 minute before fetching again\n","\n","analyze_stock(symbol)\n","\n","# Close database connection\n","conn.close()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"CKrNrXLaIo91","executionInfo":{"status":"error","timestamp":1740068575407,"user_tz":-300,"elapsed":200242,"user":{"displayName":"Hamdia Nouman","userId":"10014278124936378523"}},"outputId":"f817c629-a55b-4da3-bbfe-4e405af943eb"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Error fetching data for SPY: Too Many Requests. Rate limited. Try after a while.\n","Error fetching data for SPY: Too Many Requests. Rate limited. Try after a while.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-71e421f762b6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Fetch data 5 times with intervals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mstore_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait for 1 minute before fetching again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0manalyze_stock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":[" **Augmented Reality Transformation â€“ Perform linear algebra\n","operations like scaling, rotation, and translation.**"],"metadata":{"id":"oHdHlpOJKRdf"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# URL of the website to scrape\n","URL = \"https://www.duolingo.com/profile/HamdiaNouman\"\n","HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n","\n","# Function to fetch book details\n","def get_books(url):\n","    response = requests.get(url, headers=HEADERS)\n","    soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","    books = soup.find_all(\"article\", class_=\"product_pod\")\n","    book_list = []\n","\n","    for book in books:\n","        title = book.h3.a[\"title\"]\n","        price = book.find(\"p\", class_=\"price_color\").text\n","        stock = book.find(\"p\", class_=\"instock availability\").text.strip()\n","\n","        book_list.append({\n","            \"Title\": title,\n","            \"Price\": price,\n","            \"Availability\": stock\n","        })\n","\n","    return book_list\n","\n","# Fetch book data and save it to a CSV file\n","books_data = get_books(URL)\n","df = pd.DataFrame(books_data)\n","df.to_csv(\"books.csv\", index=False)\n","\n","print(\"Data saved to books.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C6LAvI4BKX8j","executionInfo":{"status":"ok","timestamp":1740068582297,"user_tz":-300,"elapsed":479,"user":{"displayName":"Hamdia Nouman","userId":"10014278124936378523"}},"outputId":"64393913-ba62-4297-e4eb-f867b3fab0b3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Data saved to books.csv\n"]}]}]}