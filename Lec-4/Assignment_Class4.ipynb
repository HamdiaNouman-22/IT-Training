{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "GQxVCY6UaufD",
    "ExecuteTime": {
     "end_time": "2025-02-16T15:14:00.279933Z",
     "start_time": "2025-02-16T15:14:00.104727Z"
    }
   },
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Basic Operations with 1D and 2D NumPy Array**"
   ],
   "metadata": {
    "id": "xLlpLJ-3bgO1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "arr_1d = np.array([1,2,3,4,5])\n",
    "arr_2d = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "\n",
    "def basic_numPy_array_operations():\n",
    "  global arr_1d,arr_2d\n",
    "  print(\"1D Array:\", arr_1d)\n",
    "  print(\"\\n2D Array: \\n\", arr_2d)\n",
    "  print(\"\\nSum of 1D Array:\", np.sum(arr_1d))\n",
    "  print(\"\\nMean of 2D Array:\", np.mean(arr_2d))\n",
    "  print(\"\\nTranspose of 2D Array:\\n\", arr_2d.T)\n",
    "\n",
    "basic_numPy_array_operations()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s5sw_gJua2BQ",
    "outputId": "d9394a36-166b-4fdf-9a1e-ae6ebc670f02",
    "ExecuteTime": {
     "end_time": "2025-02-16T15:15:16.283086Z",
     "start_time": "2025-02-16T15:15:16.215415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D Array: [1 2 3 4 5]\n",
      "\n",
      "2D Array: \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "Sum of 1D Array: 15\n",
      "\n",
      "Mean of 2D Array: 5.0\n",
      "\n",
      "Transpose of 2D Array:\n",
      " [[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Image Processing with NumPy (Indexing & Slicing in Action) "
  },
  {
   "cell_type": "code",
   "source": [
    "def processing_img():\n",
    "  image = np.random.randint(0, 256, (5, 5), dtype=np.uint8)\n",
    "  print(\"Original Image:\\n\", image)\n",
    "  cropped = image[1:4, 1:4]\n",
    "  print(\"\\nCropped Section:\\n\", cropped)\n",
    "  inverted_image = 255 - image\n",
    "  print(\"\\nInverted Image:\\n\", inverted_image)\n",
    "\n",
    "processing_img()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpDukO5mc3he",
    "outputId": "6c816810-235d-419d-e5c9-90c82b42cd4a",
    "ExecuteTime": {
     "end_time": "2025-02-16T15:15:17.773864Z",
     "start_time": "2025-02-16T15:15:17.685864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image:\n",
      " [[188  63 196 145 208]\n",
      " [  8 130 109   6 175]\n",
      " [ 68 101 109 147 158]\n",
      " [139  69  23 143 121]\n",
      " [ 17 235   9  65 155]]\n",
      "\n",
      "Cropped Section:\n",
      " [[130 109   6]\n",
      " [101 109 147]\n",
      " [ 69  23 143]]\n",
      "\n",
      "Inverted Image:\n",
      " [[ 67 192  59 110  47]\n",
      " [247 125 146 249  80]\n",
      " [187 154 146 108  97]\n",
      " [116 186 232 112 134]\n",
      " [238  20 246 190 100]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Augmented Reality Transformation – Perform linear algebra operations like scaling, rotation, and translation."
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image = cv2.imread('b4Jy0kwhnsWcsDQyuzAEsN7RmhQ.jpg') \n",
    "def scale_image(image, scale_factor):\n",
    "    new_width = int(image.shape[1] * scale_factor)\n",
    "    new_height = int(image.shape[0] * scale_factor)\n",
    "    scaled_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "    return scaled_image\n",
    " \n",
    "def rotate_image(image, angle): \n",
    "    rows, cols = image.shape[:2] \n",
    "    \n",
    "    rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, \n",
    "1) \n",
    "     \n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (cols, rows)) \n",
    "    return rotated_image \n",
    " \n",
    "def translate_image(image, tx, ty):\n",
    "    translation_matrix = np.array([[1, 0, tx], \n",
    "                                   [0, 1, ty]], dtype=np.float32)\n",
    "\n",
    "    rows, cols = image.shape[:2]\n",
    "\n",
    "    translated_image = cv2.warpAffine(image, translation_matrix, (cols, rows))\n",
    "    return translated_image\n",
    "scaled_image = scale_image(image, 1.5)\n",
    "rotated_image = rotate_image(image, 45)\n",
    "translated_image = translate_image(image, 50, 30) \n",
    " \n",
    "cv2.imshow('Original', image) \n",
    "cv2.imshow('Scaled', scaled_image) \n",
    "cv2.imshow('Rotated', rotated_image) \n",
    "cv2.imshow('Translated', translated_image) \n",
    " \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ],
   "metadata": {
    "id": "SKWV3rZedxRc",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-16T15:15:18.194358Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Face Detection from Image Arrays – Extract facial features by slicing a NumPy-based image array."
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-02-18T09:40:43.002499Z",
     "start_time": "2025-02-18T09:33:12.105265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    " \n",
    "# Load an image and convert it to a NumPy array \n",
    "image = cv2.imread('face.jpg')  # Replace with your image path \n",
    "if image is None:\n",
    "    print(\"Error: Image not loaded. Check the file path.\")\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    " \n",
    "# Load OpenCV's pre-trained Haar Cascade for face detection \n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \n",
    "'haarcascade_frontalface_default.xml') \n",
    " \n",
    "# Detect faces in the image \n",
    "faces = face_cascade.detectMultiScale(image_gray, scaleFactor=1.1, \n",
    "minNeighbors=5) \n",
    " \n",
    "# Loop through the detected faces and extract facial features (regions) \n",
    "for (x, y, w, h) in faces:\n",
    "    # Slice the image array to extract the face region \n",
    "    face_region = image[y:y+h, x:x+w] \n",
    "     \n",
    "    # Optional: Display the face region \n",
    "    cv2.imshow('Face Region', face_region) \n",
    "     \n",
    "    # Extract additional facial features if required (e.g., eyes, nose) \n",
    "    eyes_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \n",
    "'haarcascade_eye.xml') \n",
    "    eyes = eyes_cascade.detectMultiScale(face_region, scaleFactor=1.1, \n",
    "minNeighbors=5) \n",
    "     \n",
    "    for (ex, ey, ew, eh) in eyes: \n",
    "        eye_region = face_region[ey:ey+eh, ex:ex+ew] \n",
    "        cv2.imshow('Eye Region', eye_region) \n",
    " \n",
    "# Show the original image with detected faces \n",
    "cv2.imshow('Detected Faces', image) \n",
    " \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
